# k8s dns ndots

## domain searching

### _dns_ ndots

`/etc/resolv.conf` [has a ndots:N option](https://man.archlinux.org/man/resolv.conf.5.en#ndots:)
that controls how DNS searches are performed.
A very brief overview of the [algorithm used by Go](https://go.googlesource.com/go/+/aca9f4e484b529aeb15bf6f9633a5f07d9bab940/src/net/dnsclient_unix.go#496)

1. If the name is rooted (ends in `.`), use that directly.
2. If the name has sufficient number of dots (`>= ndots`), query the name directly.
3. For each search domain, prepend the name and query that.
4. If not queried in step 2, query the name directly.

K8s defaults this to `ndots:5` along with some search domains.
For example:

```resolv
search default.svc.cluster.local svc.cluster.local cluster.local
options ndots:5
```

The reasoning for why 5 can be found in [this comment](https://github.com/kubernetes/kubernetes/issues/33554#issuecomment-266251056).
It can be summed up as:
we expect the majority of DNS queries to be in-namespace, then in-cluster.
We also want them to be portable, so we end up with a very large ndots setting.

If these assumptions don't hold for your services
e.g. they primarily query names for outside the cluster,
then you might experience [perf degradation](https://pracucci.com/kubernetes-dns-resolution-ndots-options-and-why-it-may-affect-application-performances.html)
resulting from more lookups than necesaary.

I noticed this from our CoreDNS metrics where 60% of responses were NXDOMAIN...
By setting dnsConfig on our pods, we managed to reduce the queries significantly.

```yaml
apiVersion: v1
kind: Pod
spec:
  dnsConfig:
    options:
      - name: ndots
        value: "1"
```
